{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus\n",
    "- maxq (1) {1-3}: snippets por query a usar\n",
    "- nickname: individual o global (30)\n",
    "- context (False): información contextual del desafio\n",
    "- duplicates (False): solo snippets  unicos\n",
    "- sentences (False): un snippet representa un elemento del arreglo de palabras o por cada oración\n",
    "\n",
    "\n",
    "### Modelo\n",
    "- **words**\n",
    "- minimum (sujeto al tamaño del corpus)\n",
    "- sg (CBOW o SkipGram)\n",
    "- window (sujeto al tamaño del corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommendation import corpus_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `corpus_builder(challenge_id, context=False, nickname=None, maxq=1, duplicates=False, sentences=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcelo\\Desktop\\recomendacion_de_terminos\\filtering.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['snippet'] = filtered_data['snippet'].map(lambda text: BeautifulSoup(text, 'html.parser').get_text())\n"
     ]
    }
   ],
   "source": [
    "sentences = corpus_builder(challenge_id=4, maxq=3, sentences=True)\n",
    "paragraphs = corpus_builder(challenge_id=4, maxq=3, sentences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sum([len(word) for word in sentences]), len(sentences), len(paragraphs)) #total palabras, total frases, total snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculos para variable window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wxsent = [len(word) for word in sentences]\n",
    "\n",
    "wxs = pd.DataFrame(wxsent)\n",
    "\n",
    "wxs.to_csv('wxsent.csv', header=['count'], index=False)\n",
    "\n",
    "#wxsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculos para min_count\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstats = Counter(x for xs in sentences for x in set(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('auto', 473)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('foam', 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(wstats.most_common(1)[0], wstats.most_common()[-1]) #palabra con mayor/menor ocurrencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/33695220/calculate-mean-on-values-in-python-collections-counter\n",
    "\n",
    "https://stackoverflow.com/questions/10373247/how-do-i-write-a-python-dictionary-to-a-csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesario para exportar las palabras y su frecuencia\n",
    "#import csv\n",
    "\n",
    "#with open('wstats.csv','w') as f:\n",
    "    #w = csv.writer(f)\n",
    "    #w.writerows(wstats.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.713269512032974"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nth = list(wstats.values())\n",
    "np.mean(nth) #promedio de ocurrencias, hasta n veces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "Consideraciones en los parametros min_count y window correspondientemente:\n",
    "\n",
    "De 04B_Estadisticas se obtuvo:\n",
    "\n",
    "\n",
    "| Ocurrencias >= | 2     | 3     | 4   | 5     | 6   | 7   | 8  | 9    | 10    | 38 |\n",
    "|----------------|-------|-------|-----|-------|-----|-----|----|------|-------|----|\n",
    "| Contribucion   | 43.5% | 27.3% | 20% | 15.5% | 12% | 10% | 9% | 7.9% | 7.12% | 1% |\n",
    "\n",
    "\n",
    "Se estimo un promedio de 9 palabras por frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = Word2Vec(sentences, min_count=3, sg=1, window=5)\n",
    "modelB = Word2Vec(sentences, min_count=4, sg=1, window=5) \n",
    "modelC = Word2Vec(sentences, min_count=5, sg=1, window=5) # estandar\n",
    "modelD = Word2Vec(sentences, min_count=6, sg=1, window=5)  \n",
    "modelE = Word2Vec(sentences, min_count=7, sg=1, window=5)\n",
    "modelF = Word2Vec(sentences, min_count=8, sg=1, window=5)\n",
    "modelG = Word2Vec(sentences, min_count=9, sg=1, window=5)\n",
    "modelH = Word2Vec(sentences, min_count=10, sg=1, window=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.save(\"model/word2vec.modelA\")\n",
    "modelB.save(\"model/word2vec.modelB\")\n",
    "modelC.save(\"model/word2vec.modelC\")\n",
    "modelD.save(\"model/word2vec.modelD\")\n",
    "modelE.save(\"model/word2vec.modelE\")\n",
    "modelF.save(\"model/word2vec.modelF\")\n",
    "modelG.save(\"model/word2vec.modelG\")\n",
    "modelH.save(\"model/word2vec.modelH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelJ = Word2Vec(sentences, min_count=100, sg=1, window=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = list(modelJ.wv.vocab)\n",
    "display(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('auto', 0.552349865436554),\n",
       " ('hacer', 0.4852057695388794),\n",
       " ('red', 0.45489948987960815),\n",
       " ('paso', 0.4250407814979553),\n",
       " ('carreras', 0.42199739813804626),\n",
       " ('cómo', 0.4118427634239197),\n",
       " ('coches', 0.40453028678894043),\n",
       " ('race', 0.3976871371269226),\n",
       " ('coche', 0.3917315602302551),\n",
       " ('sistema', 0.3686029314994812),\n",
       " ('derby', 0.3625912070274353),\n",
       " ('diseño', 0.3526262044906616),\n",
       " ('motor', 0.348418653011322),\n",
       " ('autos', 0.3254251182079315),\n",
       " ('crear', 0.31388455629348755),\n",
       " ('vehículo', 0.3000103533267975),\n",
       " ('puede', 0.29629218578338623),\n",
       " ('carro', 0.2828577160835266),\n",
       " ('automóvil', 0.2736097574234009),\n",
       " ('soapbox', 0.27032265067100525),\n",
       " ('forma', 0.2611692547798157),\n",
       " ('automóviles', 0.2597395181655884),\n",
       " ('cada', 0.24054044485092163),\n",
       " ('parte', 0.23025847971439362),\n",
       " ('car', 0.21799659729003906),\n",
       " ('carrera', 0.21451954543590546),\n",
       " ('soap', 0.21371904015541077),\n",
       " ('partes', 0.2067471742630005),\n",
       " ('componentes', 0.1819603145122528),\n",
       " ('construcción', 0.1677522212266922),\n",
       " ('tipo', 0.15945743024349213),\n",
       " ('vehículos', 0.08476188033819199)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(modelJ.wv.most_similar(['construir'], topn=100))\n",
    "except KeyError:\n",
    "    print(\"Esta palabra no aparece en el modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
